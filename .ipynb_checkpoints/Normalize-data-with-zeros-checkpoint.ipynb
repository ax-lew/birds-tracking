{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.sql.SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levanto los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"datos/\"\n",
    "FILE_COORDENADAS = \"DistancesCoordenadasUTM.csv\"\n",
    "FILE_CALIBRACION = \"DatosCalibracion.csv\"\n",
    "FILE_RECEPTORES = [\"DatosRC1.csv\", \"DatosRC2.csv\", \"DatosD1.csv\", \"DatosD2.csv\"] \n",
    "\n",
    "def rdd_from_file(filename):\n",
    "    return sc.read.csv(filename, header=True, inferSchema=True).rdd\n",
    "\n",
    "coord_rdd = rdd_from_file(DIR+FILE_COORDENADAS)\n",
    "cal_rdd = rdd_from_file(DIR+FILE_CALIBRACION)\n",
    "recep_rdd = [rdd_from_file(DIR+name) for name in FILE_RECEPTORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all(list_rdd, f):\n",
    "    return list(map(f, list_rdd)) \n",
    "\n",
    "def remove_no_receptions(l):\n",
    "    return list(filter(lambda e: e > 0,l))\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro los datos de calibraci√≥n vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rdd = cal_rdd.filter(lambda x: x['Fecha'] != 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro datos de receptores invalidos (hay invalidos porque se repite el header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.filter(lambda row: row['Date'] is not None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix fechas ambiguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "global pattern\n",
    "pattern = re.compile('[1-9][0-9]*/[1-9][0-9]*/.*')\n",
    "\n",
    "def fix_date_format(row, field):\n",
    "    row_dict = row.asDict()\n",
    "    date = row[field]\n",
    "    format_from = '%m/%d/%Y'\n",
    "    format_to = '%d/%m/%Y'\n",
    "    if pattern.match(date):\n",
    "        row_dict[field] = datetime.strptime(date, format_from).strftime(format_to)\n",
    "    return row_dict\n",
    "\n",
    "cal_rdd = cal_rdd.map(lambda x: fix_date_format(x,'Fecha'))\n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.map(lambda x: fix_date_format(x, 'Date'))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp(row, date_field, time_field, suffix = ''):\n",
    "    row_dict = row if isinstance(row, (dict)) else row.asDict()\n",
    "    row_dict['timestamp'+suffix] = datetime.strptime(row[date_field]+' '+ row[time_field], '%d/%m/%Y %H:%M:%S')\n",
    "    return row_dict\n",
    "    \n",
    "cal_rdd = cal_rdd.map(lambda x: add_timestamp(x, 'Fecha', 'Inicio', '_inicio')).map(lambda x: add_timestamp(x, 'Fecha', 'Fin', '_fin'))\n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.map(lambda x: add_timestamp(x, 'Date', 'Time'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saco recepciones de pajaros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_tags = cal_rdd.map(lambda x: int(x['Tag'])).distinct().collect()\n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.filter(lambda x: x['Tag ID'] in cal_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego las recepeciones de las antenas por cada periodo de emision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "global recibidos_by\n",
    "recibidos_by = [recep_rdd[i].collect() for i in range(len(recep_rdd))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_seconds(recep, to_sec):\n",
    "    timestamp = recep[1]\n",
    "    recep_seconds = timestamp.second\n",
    "    diff_mod = abs((recep_seconds%5) - (to_sec%5))\n",
    "    delta = min(diff_mod, 5-diff_mod)\n",
    "    if ((recep_seconds-delta)%5) == (to_sec%5):\n",
    "        new_timestamp = timestamp-timedelta(seconds=delta)\n",
    "    else:\n",
    "        new_timestamp = timestamp+timedelta(seconds=delta)\n",
    "    return (new_timestamp, recep[0])\n",
    "\n",
    "def add_recep(calibr):\n",
    "    for i in range(len(recibidos_by)):\n",
    "        recepciones = []\n",
    "        start_time = calibr['timestamp_inicio']\n",
    "        all_recepcions = (\n",
    "            list(map(lambda x: (x['Power'], x['timestamp']), filter(lambda x: int(calibr['Tag']) == x['Tag ID'] and start_time <= x['timestamp'] and x['timestamp'] < calibr['timestamp_fin'], recibidos_by[i])))\n",
    "        )\n",
    "        if len(all_recepcions) == 0:\n",
    "            recepciones.extend([0]*24)\n",
    "            continue\n",
    "        else:\n",
    "            first_recep_sec = all_recepcions[0][1].second\n",
    "            print(all_recepcions)\n",
    "            all_recepcions = list(map(lambda x: normalize_seconds(x, first_recep_sec), all_recepcions))\n",
    "            recep_time_to_power = dict(all_recepcions)\n",
    "            #print(all_recepcions)\n",
    "            print(recep_time_to_power)\n",
    "            assert len(recep_time_to_power) == len(all_recepcions)\n",
    "\n",
    "            start_time = start_time + timedelta(seconds=first_recep_sec%5)\n",
    "            for emision in range(24):\n",
    "                print(start_time)\n",
    "                recepciones.append(recep_time_to_power.get(start_time, 0))\n",
    "                start_time=start_time+timedelta(seconds=5)\n",
    "                    \n",
    "        calibr['recep_{}'.format(i)] = recepciones\n",
    "\n",
    "    return calibr\n",
    "\n",
    "cal_rdd = cal_rdd.map(add_recep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add_recep(cal_rdd.filter(lambda x: x['Punto'] == 148).take(1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego datos de la 4ta antena a todos las emisiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rdd_df = cal_rdd.toDF(sampleRatio=0.2)\n",
    "\n",
    "def fix_null_recep(row):\n",
    "    row_dict = row.asDict()\n",
    "    if row_dict['recep_3'] is None:\n",
    "        row_dict['recep_3'] = [0] * 24\n",
    "    return row_dict\n",
    "\n",
    "join=cal_rdd_df.drop('recep_3').join(cal_rdd_df.filter('sort_array(recep_3, False)[0] <> 0').select('Punto', 'recep_3'), 'Punto', 'left_outer')\n",
    "\n",
    "cal_rdd = join.rdd.map(fix_null_recep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saco emisiones exactamente iguales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rdd = cal_rdd.groupBy(lambda x: (x['Punto'], x['Tag'], str(x['recep_0']+x['recep_1']+x['recep_2']+x['recep_3']))).map(lambda x: list(x[1])[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saco emisiones de la 4ta antena si ya estan en otra emision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_with_4th_and_other_emission = cal_rdd.filter(lambda x: any(x['recep_3'])).groupBy(lambda x: x['Punto']).map(lambda x: (x[0],len(list(x[1])))).filter(lambda x: x[1] > 1)\n",
    "points_list = points_with_4th_and_other_emission.map(lambda x: x[0]).collect()\n",
    "cal_rdd = cal_rdd.filter(lambda x: not(x['Punto'] in points_list and not any(x['recep_0']+x['recep_1']+x['recep_2'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego posicion de los puntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "global dict_coordenadas\n",
    "coordenadas_UTM = sc.read.csv('datos/DistancesCoordenadasUTM.csv', header=True, inferSchema=True).rdd\n",
    "dict_coordenadas = coordenadas_UTM.map(lambda x: (x['Punto'],(x['X'], x['Y']))).collectAsMap()\n",
    "\n",
    "\n",
    "def add_coord(row):\n",
    "    coordinadas = dict_coordenadas[row['Punto']]\n",
    "    row['x'] = coordinadas[0]\n",
    "    row['y'] = coordinadas[1]\n",
    "    return row\n",
    "\n",
    "cal_rdd = cal_rdd.map(add_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def my_converter(o):\n",
    "    if isinstance(o, datetime):\n",
    "        return o.__str__()\n",
    "    \n",
    "\n",
    "cal_rdd.map(lambda x: json.dumps(x, default=my_converter)).saveAsTextFile('datos/points-recep-with-zeros.jsonlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
