{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "sc = pyspark.sql.SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levanto los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"datos/\"\n",
    "FILE_COORDENADAS = \"DistancesCoordenadasUTM.csv\"\n",
    "FILE_CALIBRACION = \"DatosCalibracion.csv\"\n",
    "FILE_RECEPTORES = [\"DatosRC1.csv\", \"DatosRC2.csv\", \"DatosD1.csv\", \"DatosD2.csv\"] \n",
    "\n",
    "def rdd_from_file(filename):\n",
    "    return sc.read.csv(filename, header=True, inferSchema=True).rdd\n",
    "\n",
    "\n",
    "cal_rdd = rdd_from_file(DIR+FILE_CALIBRACION)\n",
    "recep_rdd = [rdd_from_file(DIR+name) for name in FILE_RECEPTORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all(list_rdd, f):\n",
    "    return list(map(f, list_rdd)) \n",
    "\n",
    "def remove_no_receptions(l):\n",
    "    return filter(lambda e: e > 0,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro los datos de calibraci√≥n vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rdd = cal_rdd.filter(lambda x: x['Fecha'] != 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro datos de receptores invalidos (hay invalidos porque se repite el header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.filter(lambda row: row['Date'] is not None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix fechas ambiguas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "pattern = re.compile('[1-9][0-9]*/[1-9][0-9]*/.*')\n",
    "global pattern\n",
    "\n",
    "def fix_date_format(row, field):\n",
    "    row_dict = row.asDict()\n",
    "    date = row[field]\n",
    "    format_from = '%m/%d/%Y'\n",
    "    format_to = '%d/%m/%Y'\n",
    "    if pattern.match(date):\n",
    "        row_dict[field] = datetime.strptime(date, format_from).strftime(format_to)\n",
    "    return row_dict\n",
    "\n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.map(lambda x: fix_date_format(x, 'Date'))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp(row, date_field, time_field, suffix = ''):\n",
    "    row_dict = row if isinstance(row, (dict)) else row.asDict()\n",
    "    row_dict['timestamp'+suffix] = datetime.strptime(row[date_field]+' '+ row[time_field], '%d/%m/%Y %H:%M:%S')\n",
    "    return row_dict\n",
    "    \n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.map(lambda x: add_timestamp(x, 'Date', 'Time'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saco recepciones que no son de pajaros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_tags = cal_rdd.map(lambda x: int(x['Tag'])).distinct().collect()\n",
    "birds_recep_rdd = apply_all(recep_rdd, lambda recep: recep.filter(lambda x: x['Tag ID'] not in cal_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "aux = datetime.strptime('28/01/2018 12:46:46', '%d/%m/%Y %H:%M:%S')\n",
    "aux2 = aux.replace(second=0)\n",
    "print(aux)\n",
    "print(aux2)\n",
    "'''\n",
    "int(30.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupo emisiones cada 30 seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_time = 30\n",
    "\n",
    "def merge_recep(grouped_data):\n",
    "    recepciones = grouped_data[1]\n",
    "    return {\n",
    "        'Tag': grouped_data[0][0],\n",
    "        'timestamp': grouped_data[0][1],\n",
    "        'recep': [recep['Power'] for recep in grouped_data[1]],\n",
    "    }\n",
    "    \n",
    "#birds_recep_rdd[0].groupBy(lambda x: (x['Tag ID'], x['timestamp'].replace(second=int(x['timestamp'].second/bin_time)))).map(merge_recep).take(1)\n",
    "birds_recep_rdd = apply_all(birds_recep_rdd, lambda recep: recep.groupBy(lambda x: (x['Tag ID'], x['timestamp'].replace(second=int(x['timestamp'].second/bin_time)))).map(merge_recep))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupo las 4 antenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alew/py3/lib/python3.6/site-packages/pyspark/sql/session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "birds_recep_0_df = birds_recep_rdd[0].toDF().selectExpr('*', 'recep as recep_0').alias('recep')\n",
    "birds_recep_1_df = birds_recep_rdd[1].toDF().alias('recep_1')\n",
    "birds_recep_2_df = birds_recep_rdd[2].toDF().alias('recep_2')\n",
    "birds_recep_3_df = birds_recep_rdd[3].toDF().alias('recep_3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merge1 = birds_recep_0_df.join(birds_recep_1_df, (birds_recep_0_df['Tag ID'] == birds_recep_1_df['Tag ID']) & (birds_recep_0_df.timestamp == birds_recep_1_df.timestamp), how='full')\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_time = \"\"\"case when recep.timestamp is not null then recep.timestamp\n",
    "            else case when recep_1.timestamp is not null then recep_1.timestamp\n",
    "                end\n",
    "            end as timestamp\"\"\"\n",
    "cond_tag = \"\"\"case when recep.`Tag ID` is not null then recep.`Tag ID`\n",
    "            else case when recep_1.`Tag ID` is not null then recep_1.`Tag ID`\n",
    "                end\n",
    "            end as `Tag ID`\"\"\"\n",
    "\n",
    "\n",
    "merge1 = merge1.selectExpr(cond_tag, cond_time, 'recep.recep_0', 'recep_1.recep as recep_1').alias('recep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge1.join(birds_recep_2_df, (merge1['Tag ID'] == birds_recep_2_df['Tag ID']) & (merge1.timestamp == birds_recep_2_df.timestamp), how='full')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge2 = merge2.selectExpr(cond_tag.replace('recep_1', 'recep_2'), cond_time.replace('recep_1', 'recep_2'), 'recep.recep_0', 'recep.recep_1', 'recep_2.recep as recep_2').alias('recep')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Tag ID=1, timestamp=datetime.datetime(2018, 2, 21, 7, 21), recep_0=[34], recep_1=None, recep_2=None)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge3 = merge2.join(birds_recep_3_df, (merge2['Tag ID'] == birds_recep_3_df['Tag ID']) & (merge2.timestamp == birds_recep_3_df.timestamp), how='full')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_all_df = merge3.selectExpr(cond_tag.replace('recep_1', 'recep_3'), cond_time.replace('recep_1', 'recep_3'), 'recep.recep_0', 'recep.recep_1', 'recep.recep_2', 'recep_3.recep as recep_3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change null to empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_null_recep(row):\n",
    "    row_dict = row.asDict()\n",
    "    for i in range(4):\n",
    "        if row_dict['recep_{}'.format(i)] is None:\n",
    "            row_dict['recep_{}'.format(i)] = []\n",
    "    return row_dict\n",
    "    \n",
    "\n",
    "merge_all = merge_all_df.rdd.map(fix_null_recep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def my_converter(o):\n",
    "    if isinstance(o, datetime):\n",
    "        return o.__str__()\n",
    "    \n",
    "\n",
    "merge_all.map(lambda x: json.dumps(x, default=my_converter)).saveAsTextFile('datos/birds-recep.jsonlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
