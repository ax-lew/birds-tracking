{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.sql.SparkSession.Builder().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levanto los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"datos/20-01-18/\"\n",
    "\n",
    "FILE_CALIBRACION = \"datos/DatosCalibracion.csv\"\n",
    "FILE_RECEPTORES = [\"rec1.csv\", \"rec2.csv\", \"rd1.csv\", \"rd2.csv\"] \n",
    "\n",
    "def rdd_from_file(filename):\n",
    "    return sc.read.csv(filename, header=True, inferSchema=True).rdd\n",
    "\n",
    "\n",
    "cal_rdd = rdd_from_file(FILE_CALIBRACION)\n",
    "recep_rdd = [rdd_from_file(DIR+name) for name in FILE_RECEPTORES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all(list_rdd, f):\n",
    "    return list(map(f, list_rdd)) \n",
    "\n",
    "def remove_no_receptions(l):\n",
    "    return filter(lambda e: e > 0,l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtro los datos de calibraci√≥n vacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_rdd = cal_rdd.filter(lambda x: x['Fecha'] != 'NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrego timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timestamp(row, date_field, time_field, suffix = ''):\n",
    "    row_dict = row if isinstance(row, (dict)) else row.asDict()\n",
    "    row_dict['timestamp'+suffix] = datetime.strptime(row[date_field]+' '+ row[time_field], '%m/%d/%y %H:%M:%S')\n",
    "    return row_dict\n",
    "    \n",
    "recep_rdd = apply_all(recep_rdd, lambda recep: recep.map(lambda x: add_timestamp(x, 'Date', 'Time'))) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saco recepciones que no son de pajaros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_tags = cal_rdd.map(lambda x: int(x['Tag'])).distinct().collect()\n",
    "cal_tags.append(999)\n",
    "birds_recep_rdd = apply_all(recep_rdd, lambda recep: recep.filter(lambda x: x['Tag ID'] not in cal_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Junto todas las antenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_birds_recep = birds_recep_rdd[0].union(birds_recep_rdd[1]).union(birds_recep_rdd[2]).union(birds_recep_rdd[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordeno por fecha de manera creciente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_birds_recep = merged_birds_recep.sortBy(lambda x: x['timestamp'].timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_diff(time1, time2):\n",
    "    return abs((time1-time2).total_seconds())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_antennas_recep(receptions):\n",
    "    res = []\n",
    "    last_recep_timestamp = datetime.min\n",
    "    for recep in receptions:\n",
    "        timestamp = recep['timestamp']\n",
    "        if time_diff(timestamp, last_recep_timestamp) <= 2:\n",
    "            if all([e['Antenna'] != recep['Antenna'] for e in res[-1]]):\n",
    "                res[-1].append(recep)\n",
    "        else:\n",
    "            res.append([recep])\n",
    "        last_recep_timestamp = timestamp\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_grouped_emissions(group_emissions, tag_id):\n",
    "    recep_0,recep_1,recep_2,recep_3 = 0,0,0,0\n",
    "    for e in group_emissions:\n",
    "        if e['Antenna'] == 'rec1':    \n",
    "            recep_0 = e['Power']\n",
    "        elif e['Antenna'] == 'rect':    \n",
    "            recep_1 = e['Power']\n",
    "        elif e['Antenna'] == 'rd1':    \n",
    "            recep_2 = e['Power']\n",
    "        elif e['Antenna'] == 'rd2':    \n",
    "            recep_3 = e['Power']\n",
    "    return {\n",
    "        'tag_id': tag_id,\n",
    "        'timestamp': group_emissions[0]['timestamp'],\n",
    "        'recep_0': recep_0,\n",
    "        'recep_1': recep_1,\n",
    "        'recep_2': recep_2,\n",
    "        'recep_3': recep_3,\n",
    "    }\n",
    "    \n",
    "    \n",
    "    \n",
    "def format_antennas_recep(group_emissions, tag_id):\n",
    "    return list(map(lambda x: format_grouped_emissions(x, tag_id), group_emissions))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "birds_tags = merged_birds_recep.map(lambda x: x['Tag ID']).distinct().collect()\n",
    "\n",
    "all_receptions_by_birds = []\n",
    "for i in range(len(birds_tags)):\n",
    "    bird_reception = merged_birds_recep.filter(lambda x: x['Tag ID'] == birds_tags[i]).collect()\n",
    "    grouped_emissions = group_antennas_recep(bird_reception)\n",
    "    all_receptions_by_birds.extend(format_antennas_recep(grouped_emissions, birds_tags[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_receptions_rdd = pyspark.SparkContext.getOrCreate().parallelize(all_receptions_by_birds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def my_converter(o):\n",
    "    if isinstance(o, datetime):\n",
    "        return o.__str__()\n",
    "    \n",
    "\n",
    "all_receptions_rdd.map(lambda x: json.dumps(x, default=my_converter)).saveAsTextFile('datos/day-birds.jsonlines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
